{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Only_negative_tweets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU6-h5x3w9ds"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import tweepy\n",
        "import json\n",
        "import pandas as pd\n",
        "from pandas.io.json import json_normalize \n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "print(\"silence please!!!\")"
      ],
      "metadata": {
        "id": "QzUmtzKgyFKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from PIL import Image\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from langdetect import detect\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "gXXyzQMYyFYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "WbHZoTrKyFfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New dataframe columns\n",
        "positive  = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "polarity = 0\n",
        "tweet_list = []\n",
        "neutral_list = []\n",
        "negative_list = []\n",
        "positive_list = []"
      ],
      "metadata": {
        "id": "RIq-i_UPyS2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_df = pd.read_excel(\"mustang_mach_e041022.xlsx\")\n",
        "tweets = keyword_df.full_text"
      ],
      "metadata": {
        "id": "4FD4Z5mfyS7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def percentage(part,whole):\n",
        "    return 100 * float(part)/float(whole)"
      ],
      "metadata": {
        "id": "MLbzWKA8zRhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noOfTweet = len(keyword_df)\n",
        "\n",
        "for tweet in tweets:\n",
        "    \n",
        "    #print(tweet.text)\n",
        "    tweet_list.append(tweet)\n",
        "    analysis = TextBlob(tweet)\n",
        "    score = SentimentIntensityAnalyzer().polarity_scores(tweet)\n",
        "    neg = score['neg']\n",
        "    neu = score['neu']\n",
        "    pos = score['pos']\n",
        "    comp = score['compound']\n",
        "    polarity += analysis.sentiment.polarity\n",
        "    \n",
        "    if neg > pos:\n",
        "        negative_list.append(tweet)\n",
        "        negative += 1\n",
        "\n",
        "    elif pos > neg:\n",
        "        positive_list.append(tweet)\n",
        "        positive += 1\n",
        "    \n",
        "    elif pos == neg:\n",
        "        neutral_list.append(tweet)\n",
        "        neutral += 1\n",
        "\n",
        "positive = percentage(positive, noOfTweet)\n",
        "negative = percentage(negative, noOfTweet)\n",
        "neutral = percentage(neutral, noOfTweet)\n",
        "polarity = percentage(polarity, noOfTweet)\n",
        "positive = format(positive, '.1f')\n",
        "negative = format(negative, '.1f')\n",
        "neutral = format(neutral, '.1f')"
      ],
      "metadata": {
        "id": "Y4IFb2J6yTAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_list = pd.DataFrame(tweet_list)\n",
        "neutral_list = pd.DataFrame(neutral_list)\n",
        "negative_list = pd.DataFrame(negative_list)\n",
        "positive_list = pd.DataFrame(positive_list)\n",
        "print(\"total number: \",len(tweet_list))\n",
        "print(\"positive number: \",len(positive_list))\n",
        "print(\"negative number: \", len(negative_list))\n",
        "print(\"neutral number: \",len(neutral_list))"
      ],
      "metadata": {
        "id": "0S_S_7OQyTE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Positive ['+str(positive)+'%]' , 'Neutral ['+str(neutral)+'%]','Negative ['+str(negative)+'%]']\n",
        "sizes = [positive, neutral, negative]\n",
        "colors = ['yellowgreen', 'blue','red']\n",
        "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
        "plt.style.use('default')\n",
        "plt.legend(labels)\n",
        "plt.title(\"Sentiment Analysis Result for account= mrpotholeuk\" )\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rartmrflyTJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_list.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "g6zmqN_vyTM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tw_list = pd.DataFrame(tweet_list)\n",
        "tw_list[\"text\"] = tw_list[0]\n",
        "tw_list"
      ],
      "metadata": {
        "id": "PkuPNOXYzp_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new dataframe and new features\n",
        "tw_list = pd.DataFrame(tweet_list)\n",
        "tw_list[\"text\"] = tw_list[0]\n",
        "\n",
        "#Removing RT, Punctuation etc\n",
        "remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n",
        "rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
        "tw_list[\"text\"] = tw_list.text.map(remove_rt).map(rt)\n",
        "tw_list[\"text\"] = tw_list.text.str.lower()\n",
        "tw_list.head(10)"
      ],
      "metadata": {
        "id": "HsDunzczzqDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tw_list[['polarity', 'subjectivity']] = tw_list['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
        "for index, row in tw_list['text'].iteritems():\n",
        "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
        "    neg = score['neg']\n",
        "    neu = score['neu']\n",
        "    pos = score['pos']\n",
        "    comp = score['compound']\n",
        "    if neg > pos:\n",
        "        tw_list.loc[index, 'sentiment'] = \"negative\"\n",
        "    elif pos > neg:\n",
        "        tw_list.loc[index, 'sentiment'] = \"positive\"\n",
        "    else:\n",
        "        tw_list.loc[index, 'sentiment'] = \"neutral\"\n",
        "    tw_list.loc[index, 'neg'] = neg\n",
        "    tw_list.loc[index, 'neu'] = neu\n",
        "    tw_list.loc[index, 'pos'] = pos\n",
        "    tw_list.loc[index, 'compound'] = comp\n",
        "\n",
        "tw_list.head(10)"
      ],
      "metadata": {
        "id": "ufkp-EzWzqLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new data frames for all sentiments (positive, negative and neutral)\n",
        "\n",
        "tw_list_negative = tw_list[tw_list[\"sentiment\"]==\"negative\"]\n",
        "tw_list_positive = tw_list[tw_list[\"sentiment\"]==\"positive\"]\n",
        "tw_list_neutral = tw_list[tw_list[\"sentiment\"]==\"neutral\"]"
      ],
      "metadata": {
        "id": "Or6i3CfCz0pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for count_values_in single columns\n",
        "\n",
        "def count_values_in_column(data,feature):\n",
        "    total=data.loc[:,feature].value_counts(dropna=False)\n",
        "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
        "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])"
      ],
      "metadata": {
        "id": "nvG073QSz0lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count_values for sentiment\n",
        "count_values_in_column(tw_list,\"sentiment\")"
      ],
      "metadata": {
        "id": "OiUZQBkfz0vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SozFln2rz0yT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}